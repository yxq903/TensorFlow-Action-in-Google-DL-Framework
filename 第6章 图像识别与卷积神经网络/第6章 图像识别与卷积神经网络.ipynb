{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  环境2：阿里云 ubuntu  python27 tensorflowf1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  环境2：小米Air  Win10  python3 tensorflowf1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 图像识别问题简介及经典数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR数据集简介：\n",
    "（1）10个不同种类60000张图片\n",
    "（2）像素是32*32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ImageNet是一个基于WordNet的大型图像数据库。在其中，近1500万张图片关联到WordNet的20000个名词同义词集上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 卷积神经网络简介 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对与卷积神经网络，相邻两层之间只有部分节点相连，为了展示每一层神经元的维度，一般会将每一层卷积层的节点组织成一个三维矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卷积神经网络的结构组成：\n",
    "1. 输入层\n",
    "2. 卷积层：通过卷积层处理过的节点矩阵会变深；\n",
    "3. 池化层：池化层不会改变三维矩阵的深度但是会缩小矩阵的大小。\n",
    "4. 全连接层：可以将卷积层和池化层看成自动图像特征提取的过程。在特征提取完之后仍然需要使用全连接层完成分类任务。\n",
    "5. Softmax层;主要用于分类问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 卷积神经网络常用的结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 过滤器（内核）：可以将当前神经网络上的一个子结点矩阵转化为下一层神经网络上一个单位节点矩阵（长宽为1，深度不限）。\n",
    "- 过滤器的长和宽是人工指定的。常用过滤器尺寸有3×3、5×5。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果要避免尺寸变化，可以在当前层矩阵边界填充0\n",
    "\n",
    "![1755](../TfInActionImg/1755.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在同时使用全0填充时结果矩阵的大小\n",
    "![1800](../TfInActionImg/1800.PNG)\n",
    "- 不使用0填充的结果矩阵大小\n",
    "![1801](../TfInActionImg/1801.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在卷积神经网络中，每一个卷积层中使用的过滤器参数都是一样的，这样使得图像上的内容不受位置影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no-exe code\n",
    "# Tensorflow实现卷积层样例：\n",
    "\n",
    "filter_weight = tf.get_variable(\n",
    "    'weights',[5,5,3,6],#过滤器尺寸5*5，深度3，当前层节点矩阵深度16\n",
    "    initializer = tf.truncated_normal_initializer(stddev = 0.1)\n",
    ")\n",
    "biases = tf.get_variable(\n",
    "    'biases',[16], #过滤器的深度，同时也是下一层节点的矩阵深度\n",
    "    initializer = tf.constant_initializer(0.1)\n",
    ")\n",
    "conv = tf.nn.conv2d(\n",
    "    input,#四维数，后三维表示当前层节点矩阵，比如input[2,:,:,:]表示第三张图片\n",
    "    filter_weight,# 卷积层权重\n",
    "    strides = [1,1,1,1],# 不同维度上的步长但是第一个和最后一个数必须是1\n",
    "    padding = 'SAME'# SAME表示添加全0填充，VALID表示不添加bias\n",
    ")\n",
    "bias = tf.nn.bias_add(conv,biases) # ???\n",
    "actived_conv = tf.nn.relu(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 池化层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 池化层作用：\n",
    "- 缩小矩阵尺寸，从而减少全连接层中的参数；\n",
    "- 使用池化层既可以加快计算速度也有防止过拟合问题的作用；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 常用的池化层： 最大池化层、平均池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no-exe code\n",
    "# Tensorflow实现池化层样例：\n",
    "pool = tf.nn.max_pool(\n",
    "    actived_conv,\n",
    "    ksize = [1,3,3,1],\n",
    "    strides = [1,2,2,1],\n",
    "    padding = 'SAME'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 经典卷积网络模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 LeNet-5 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 每层参数数目分析：\n",
    "![2030](../TfInActionImg/2030.PNG)\n",
    "![2031](../TfInActionImg/2031.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow实现CNN示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\softwareYXQ\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-715d9e0653f7>:66: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\softwareYXQ\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\softwareYXQ\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\softwareYXQ\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\softwareYXQ\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\softwareYXQ\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "After 1 training step(s), loss on training batch is 4.66097.\n",
      "After 101 training step(s), loss on training batch is 1.12016.\n",
      "After 201 training step(s), loss on training batch is 0.928684.\n",
      "After 301 training step(s), loss on training batch is 0.799152.\n",
      "After 401 training step(s), loss on training batch is 0.839283.\n",
      "After 501 training step(s), loss on training batch is 0.813232.\n",
      "After 601 training step(s), loss on training batch is 0.77802.\n",
      "After 701 training step(s), loss on training batch is 0.675622.\n"
     ]
    }
   ],
   "source": [
    "# LeNet5_train\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import LeNet5_infernece\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 1. 定义神经网络相关的参数\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE_BASE = 0.01\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "TRAINING_STEPS = 800\n",
    "MOVING_AVERAGE_DECAY = 0.99\n",
    "\n",
    "# 2.定义训练过程\n",
    "def train(mnist):\n",
    "    # 定义输出为4维矩阵的placeholder\n",
    "    x = tf.placeholder(tf.float32, [\n",
    "            BATCH_SIZE,\n",
    "            LeNet5_infernece.IMAGE_SIZE,\n",
    "            LeNet5_infernece.IMAGE_SIZE,\n",
    "            LeNet5_infernece.NUM_CHANNELS],\n",
    "        name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, LeNet5_infernece.OUTPUT_NODE], name='y-input')\n",
    "    \n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    y = LeNet5_infernece.inference(x,False,regularizer)\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    # 定义损失函数、学习率、滑动平均操作以及训练过程。\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    loss = cross_entropy_mean + tf.add_n(tf.get_collection('losses'))\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,\n",
    "        global_step,\n",
    "        mnist.train.num_examples / BATCH_SIZE, LEARNING_RATE_DECAY,\n",
    "        staircase=True)\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "        \n",
    "    # 初始化TensorFlow持久化类。\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "\n",
    "            reshaped_xs = np.reshape(xs, (\n",
    "                BATCH_SIZE,\n",
    "                LeNet5_infernece.IMAGE_SIZE,\n",
    "                LeNet5_infernece.IMAGE_SIZE,\n",
    "                LeNet5_infernece.NUM_CHANNELS))\n",
    "            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: reshaped_xs, y_: ys})\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(\"After %d training step(s), loss on training batch is %g.\" % (step, loss_value))\n",
    "                \n",
    "# 3.主程序入口\n",
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"../data/mnist/\", one_hot=True)\n",
    "    \n",
    "    train(mnist)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.reset_default_graph() \n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卷积神经网络架构： 输入层->（卷积层+池化层?）+->全连接层+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Inception模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2117](../TfInActionImg/2117.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码见P158 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 卷积神经网络迁移学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 迁移学习介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集：http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "- 注：该数据集需要通过科学上网下载，该数据集未同步到github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码见：\n",
    "- data_process \n",
    "- fine_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
