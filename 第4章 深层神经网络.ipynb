{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  环境：阿里云 ubuntu  python27 tensorflowf1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1深度学习与深层神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 损失函数的定义\n",
    "### 4.2.1 经典损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.clip_by_value可以把张量中数值限制在某个范围内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v= tf.constant([[1.0,2.0,3.0],[4.0,5.0,6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5 2.5 3. ]\n",
      " [4.  4.5 4.5]]\n",
      "-----------------------------------\n",
      "[[0.        0.6931472 1.0986123]\n",
      " [1.3862944 1.609438  1.7917595]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    print(tf.clip_by_value(v,2.5,4.5).eval())\n",
    "    print(\"-----------------------------------\")\n",
    "    print (tf.log(v).eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5. 12.]\n",
      " [21. 32.]]\n",
      "[[19. 22.]\n",
      " [43. 50.]]\n"
     ]
    }
   ],
   "source": [
    "v1= tf.constant([[1.0,2.0],[3.0,4.0]])\n",
    "v2 = tf.constant([[5.0,6.0],[7.0,8.0]])\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    print ((v1*v2).eval())#按元素相乘\n",
    "    print(tf.matmul(v1,v2).eval())#矩阵相乘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 自定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8113182]\n",
      " [ 1.4845988]]\n",
      "[[-0.81031823]\n",
      " [ 1.4855988 ]]\n",
      "[[0.02119794]\n",
      " [2.1813974 ]]\n",
      "[[0.48111677]\n",
      " [2.3831027 ]]\n",
      "[[0.72828794]\n",
      " [2.3937883 ]]\n",
      "[[0.9094245]\n",
      " [2.3333366]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape=(None,2),name=\"x-input\")\n",
    "y_ = tf.placeholder(tf.float32,shape=(None,1),name=\"y-input\")\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((2,1),stddev=1,seed=1))\n",
    "y = tf.matmul(x,w1)\n",
    "\n",
    "#定义回归预测多了和预测少了的损失函数\n",
    "loss_less = 10\n",
    "loss_more = 1\n",
    "loss = tf.reduce_sum( tf.where(tf.greater(y,y_),(y-y_)*loss_more,(y_-y)*loss_less ))\n",
    "\n",
    "learning_rate = 0.001\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#通过随机数生成数据集\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size,2)\n",
    "#设置回归正确的数值为两个输入的和加上一个随机量。\n",
    "Y= [[x1+x2+rdm.rand()/10-0.05] for (x1,x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    #初始化变量\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    print sess.run(w1)\n",
    "    \n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        #每次选取batch个样本进行训练\n",
    "        start = (i*batch_size)%dataset_size\n",
    "        end = min(start+batch_size,dataset_size)\n",
    "        \n",
    "        #通过选取的样本外训练神经网络并更新参数\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "        if i%1000==0:\n",
    "            print (sess.run(w1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 神经网络的优化算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正则化样例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "5.0\n",
      "7.5\n"
     ]
    }
   ],
   "source": [
    "weights = tf.constant([[1.0,-2.0],[-3.0,4.0]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run( tf.contrib.layers.l1_regularizer(.5)(weights) ))\n",
    "    print(sess.run( tf.contrib.layers.l2_regularizer(.5)(weights) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算一个5层神经网络带L2正则化的损失函数的计算方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  非完整可执行代码片段\n",
    "#   ??这个代码要干啥呀！！\n",
    "import tensorflow as tf \n",
    "\n",
    "# 获取一层神经网络边的权重，并将这个权重的L2正则化损失加入到名称为‘losses’的集合中\n",
    "def get_weight(shape,lambdaa):#lambdaa!!!\n",
    "    #生成一个变量\n",
    "    var = tf.Variable(tf.random_normal(shape),dtype=tf.float32)\n",
    "    # 第一个参数是集合的名字\n",
    "    tf.add_to_collection('losses',tf.contrib.layers.l2_regularizer(lambdaa)(var))\n",
    "    return var\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape=(None,2))\n",
    "y_ = tf.placeholder(tf.float32,shape=(None,1))\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "layer_dimension = [2,10,10,10,1]\n",
    "n_layers = len(layer_dimension)\n",
    "\n",
    "#这个变量维护前向传播最深的节点，开始的时候就是输入层\n",
    "cur_layer = x\n",
    "#当前层节点的个数\n",
    "in_dimension = layer_dimension[0]\n",
    "\n",
    "# 通过一个循环生成5层全连接神经网络结构\n",
    "for i in range(1,n_layers):\n",
    "    # layer_dimension[i] 为下一层节点的个数\n",
    "    out_dimension = layer_dimension[i]\n",
    "    # 生成当前层中的变量，并将这个变量的L2正则化损失加入计算图上的集合\n",
    "    weight = get_weight([in_dimension,out_dimension],0.001)\n",
    "    bias = tf.Variable(tf.constant(0.1,shape=[out_dimension]))\n",
    "    cur_layers = tf.nn.relu(tf.matmul(cur_layers,weight) + bias)\n",
    "    # 进入下一层之前将下一层的节点个数更新为当前层节点的个数\n",
    "    in_dimension = layer_dimension[i]\n",
    "    \n",
    "mse_loss = tf.reduce_mean(tf.square(y_-cur_layer))\n",
    "\n",
    "tf.add_to_collection('losses',mse_loss)\n",
    "\n",
    "loss = tf.add_n(tf.get_collection('losses'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 滑动平均模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "[5.0, 4.5]\n",
      "[5.0, 4.95]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "v1 = tf.Variable(0,dtype=tf.float32)\n",
    "step = tf.Variable(0,trainable=False)\n",
    "\n",
    "ema = tf.train.ExponentialMovingAverage(0.99,step)\n",
    "maintain_averages_op = ema.apply([v1])\n",
    "with tf.Session() as sess:\n",
    "    #初始化所有变量\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # 初始化后变量的值以及滑动平均后的值\n",
    "    print sess.run([v1,ema.average(v1)])\n",
    "    \n",
    "    #更新v1的值到5\n",
    "    sess.run(tf.assign(v1,5))\n",
    "    sess.run(maintain_averages_op)\n",
    "    print (sess.run([v1,ema.average(v1)]))\n",
    "    \n",
    "    sess.run(maintain_averages_op)\n",
    "    print (sess.run([v1,ema.average(v1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
