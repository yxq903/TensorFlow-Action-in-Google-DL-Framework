{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  环境：阿里云 ubuntu  python27 tensorflowf1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "![789](./TfInActionImg/1313.PNG) 图片插入示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 MNIST 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 虽然MNIST数据集只提供了训练和测试数据，但是为了验证模型训练效果，一般会从训练数据中划分出一部分数据作为验证数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow提供了一个类处理该数据集，它会自动下载并转化MNIST数据的格式，下面给出它的样例程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Training data size: 55000\n",
      "Validating data size: 5000\n",
      "Testing data size: 10000\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow的MNIST类样例\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#载入数据，如果指定路径无该数据集，则会自动下载\n",
    "mnist = input_data.read_data_sets(\"./data/mnist/\",one_hot=True)\n",
    "\n",
    "# 打印训练数据大小\n",
    "print \"Training data size:\",mnist.train.num_examples\n",
    "\n",
    "# 打印验证数据大小\n",
    "print \"Validating data size:\",mnist.validation.num_examples\n",
    "\n",
    "# 打印测试数据大小\n",
    "print \"Testing data size:\",mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data example: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.3803922  0.37647063 0.3019608\n",
      " 0.46274513 0.2392157  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.3529412\n",
      " 0.5411765  0.9215687  0.9215687  0.9215687  0.9215687  0.9215687\n",
      " 0.9215687  0.9843138  0.9843138  0.9725491  0.9960785  0.9607844\n",
      " 0.9215687  0.74509805 0.08235294 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.54901963 0.9843138  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.7411765  0.09019608 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.8862746  0.9960785  0.81568635 0.7803922  0.7803922  0.7803922\n",
      " 0.7803922  0.54509807 0.2392157  0.2392157  0.2392157  0.2392157\n",
      " 0.2392157  0.5019608  0.8705883  0.9960785  0.9960785  0.7411765\n",
      " 0.08235294 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.14901961 0.32156864\n",
      " 0.0509804  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.13333334 0.8352942  0.9960785  0.9960785  0.45098042 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32941177\n",
      " 0.9960785  0.9960785  0.9176471  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.32941177 0.9960785  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4156863  0.6156863  0.9960785  0.9960785  0.95294124 0.20000002\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.09803922\n",
      " 0.45882356 0.8941177  0.8941177  0.8941177  0.9921569  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.94117653 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.26666668 0.4666667  0.86274517 0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.5568628  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.14509805 0.73333335 0.9921569\n",
      " 0.9960785  0.9960785  0.9960785  0.8745099  0.8078432  0.8078432\n",
      " 0.29411766 0.26666668 0.8431373  0.9960785  0.9960785  0.45882356\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4431373  0.8588236  0.9960785  0.9490197  0.89019614 0.45098042\n",
      " 0.34901962 0.12156864 0.         0.         0.         0.\n",
      " 0.7843138  0.9960785  0.9450981  0.16078432 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.6627451  0.9960785\n",
      " 0.6901961  0.24313727 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.18823531 0.9058824  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.07058824 0.48627454 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.32941177 0.9960785  0.9960785  0.6509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.54509807\n",
      " 0.9960785  0.9333334  0.22352943 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.8235295  0.9803922  0.9960785  0.65882355\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.9490197  0.9960785  0.93725497 0.22352943 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.34901962 0.9843138  0.9450981\n",
      " 0.3372549  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01960784 0.8078432  0.96470594 0.6156863  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01568628 0.45882356\n",
      " 0.27058825 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# 打印训练数据示例\n",
    "print \"Training data example:\",mnist.train.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 打印训练数据标签\n",
    "print \"Training data label:\",mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1356](./TfInActionImg/1356.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (100, 784)\n",
      "Y shape: (100, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "xs,ys = mnist.train.next_batch(batch_size)\n",
    "print \"X shape:\",xs.shape\n",
    "print \"Y shape:\",ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (784,)\n"
     ]
    }
   ],
   "source": [
    "print \"Training data size:\",mnist.train.images[55].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 神经网络模型训练以及不同模型结果对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 TensorFlow训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运用第四章的方法，给出一个完整的神经网络程序\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# MNIST数据集相关的常数\n",
    "INPUT_NODE = 784                    #输入层节点数，对于该数据集相当于图片像素28*28\n",
    "OUTPUT_NODE = 10                    #输出层节点数，该数据集输出分为0~9类\n",
    "\n",
    "#配置神经网络参数\n",
    "LAYER1_NODE = 500                   #隐藏层节点数，用只有一个隐藏层的网络结构作为样例\n",
    "BATCH_SIZE  = 100                   #数字越小，越接近随机梯度下降；越大越接近梯度下降\n",
    "LEARNING_RATE_BASE = 0.8            #基础学习率\n",
    "LEARNING_RATE_DECAY = 0.99          #学习率的衰减率\n",
    "REGULARIZATION_RATE = 0.0001        #描述模型复杂程度的正则化项在损失函数中的系数\n",
    "TRAINING_STEPS      = 30000         #训练轮数\n",
    "MOVING_AVERAGE_DECAY = 0.99         #滑动平均衰减率\n",
    "\n",
    "#定义一个使用relu激活函数的三层全连接神经网络\n",
    "def inference(input_tensor,avg_class,weights1,biases1,weights2,biases2):\n",
    "    #当没有使用滑动平均类的时候直接使用参数的当前取值\n",
    "    if avg_class == None:\n",
    "        # 计算隐藏层的前向传播结果\n",
    "        layer1= tf.nn.relu(tf.matmul(input_tensor,weights1) + biases1)\n",
    "        #计算输出层的前向传播结果。计算损失函数时候会一起计算softmax函数，所以这里无激活\n",
    "        #函数。因为预测使用的是不同类别对应节点的输出值相对大小，有没有softmax层\n",
    "        #对最后分类结果计算没有影响\n",
    "        return tf.matmul(layer1,weights2) + biases2\n",
    "    \n",
    "    else:\n",
    "        layer1 = tf.nn.relu(\n",
    "            tf.matmul(input_tensor,avg_class.average(weights1)) + \\\n",
    "            avg_class.average(biases1)\n",
    "        )\n",
    "        return tf.matmul(layer1,avg_class.average(weights2)) + \\\n",
    "            avg_class.average(biases2)\n",
    "    \n",
    "# 训练模型的过程\n",
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32,[None,INPUT_NODE],name = 'x-input')\n",
    "    y_ = tf.placeholder(tf.float32,[None,OUTPUT_NODE],name = 'y-input')\n",
    "    \n",
    "    #生成隐藏层的参数\n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE,LAYER1_NODE],stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1,shape = [LAYER1_NODE]))\n",
    "    \n",
    "    #生成输出层参数\n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE,OUTPUT_NODE],stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1,shape = [OUTPUT_NODE]))\n",
    "    \n",
    "    #计算如下参数下前向传播结果\n",
    "    y = inference(x,None,weights1,biases1,weights2,biases2)\n",
    "    \n",
    "    #定义训练轮数的变量。这个变量不需要计算滑动平均值，所以指定变量为不可训练\n",
    "    global_step = tf.Variable(0,trainable=False)\n",
    "    \n",
    "    #给定华东平均衰减率和训练轮数的变量，初始化华东平均类\n",
    "    #？？因为给定训练轮数的变量可以加快训练早期变量的更新速度\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)\n",
    "    \n",
    "    # 在代表神经网络参数的变量上使用滑动平均\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    # 计算滑动平均之后的前向传播结果\n",
    "    average_y = inference(x,variable_averages,weights1,biases1,weights2,biases2)\n",
    "    \n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=y,labels=tf.argmax(y_,1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    #计算L2正则化损失函数\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    regularization = regularizer(weights1) + regularizer(weights2)\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    # 设置指数衰减的学习率\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,global_step,\n",
    "        mnist.train.num_examples/BATCH_SIZE,LEARNING_RATE_DECAY\n",
    "    )\n",
    "    \n",
    "    # 批梯度下降优化\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate)\\\n",
    "    .minimize(loss,global_step = global_step)\n",
    "    \n",
    "    #反向传播更新神经网络参数，还要更新每个参数滑动平均值\n",
    "    # train_op = tf.group(train_step,variables_averages_op)#同下面两行等价\n",
    "    with tf.control_dependencies([train_step,variables_averages_op]):\n",
    "        train_op = tf.no_op(name = \"train\")\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(average_y,1),tf.arg_max(y_,1))\n",
    "    #将布尔数值转换为实数数值，然后计算平均值即为一组数值上的正确率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    # 初始化会话并开始训练过程\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        #准备验证数据\n",
    "        #通过验证数据大致判断停止的条件和评判训练效果\n",
    "        validate_feed = {x:mnist.validation.images,y_:mnist.validation.labels}\n",
    "        \n",
    "        #准备测试数据\n",
    "        test_feed = {x:mnist.test.images,y_:mnist.test.labels}\n",
    "        \n",
    "        #迭代训练神经网络\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            if i%1000 == 0:\n",
    "                validate_acc = sess.run(accuracy,feed_dict = validate_feed)\n",
    "                print(\"After %d training step(s), validation accuracy\"\n",
    "                     \"using average model is %g\"%(i,validate_acc))\n",
    "            #产生这一轮使用的一个batch的数据，并运行训练过程\n",
    "            xs,ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op,feed_dict={x:xs,y_:ys})\n",
    "        \n",
    "        #在训练结束后，在测试数据上检测神经网络模型的最终正确率\n",
    "        test_acc = sess.run(accuracy,feed_dict=test_feed)\n",
    "        print(\"After %d training step(s), test accuracy using average\"\n",
    "                     \"model is %g\"%(TRAINING_STEPS,test_acc))\n",
    "        \n",
    "#主程序入口\n",
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"./data/mnist/\",one_hot=True)\n",
    "    train(mnist)\n",
    "    \n",
    "#Tensorflow提供一个主程序入口，tf.app.run会调用上面定义的main函数\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 使用验证数据集判读模型效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为了估计模型在未知数据的效果，需要保证测试数据在训练过程不可见"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 除了使用验证数据集，还可以使用交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 不同模型效果比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1620](./TfInActionImg/1620.PNG)\n",
    "![1626](./TfInActionImg/1626.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从下图看出，只优化交叉熵损失虽然在训练数据上比优化总损失模型更小，但是在测试数据上的正确率却不好。\n",
    "\n",
    "![1630](./TfInActionImg/1630.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
